---
show: step
version: 1.0 
enable_checker: true 
---

# 图形化报表工具对接

## 试验介绍

本课程将带领您在已经部署 SequoiaDB 巨杉数据库引擎及 SparkSQL 实例的环境中，进行 Pentaho 的安装，并进行 SparkSQL 的对接。

#### 知识点

+ Pentaho 的安装
+ Pentaho 与 SequoiaDB + SparkSQL 的对接

## Pentaho 的安装部署

#### Pentaho 简介

Pentaho 分为商业版和社区版，社区版除了不包含商业版中特有的 Pentaho Analyzer、原厂专业支持服务、技术文档等，在其他绝大部分常用功能上，与商业版保持一致。本文以社区版 7.0 为例，演示 Pentaho 与 SequoiaDB + SparkSQL 对接及使用。

Pentaho社区版（7.0）下载地址为：

```html
https://sourceforge.net/projects/pentaho/files/Business%20Intelligence%20Server/7.0/pentaho-server-ce-7.0.0.0-25.zip
```

#### Pentaho 的安装

Pentaho 下载得到的安装文件为 pentaho-server-ce-7.0.0.0-25.zip。社区版 Pentaho 安装仅需要解压安装文件到指定目录即可，适用于 Windows 和 Linux 环境。

解压 Pentaho 安装包

```
sudo unzip soft/pentaho-server-ce-7.0.0.0-25.zip -d /opt
sudo chown -R sdbadmin:sdbadmin_group /opt/pentaho-server
```

## Pentaho 对接 SequoiaDB + Spark SQL

#### 配置 SparkSQL 驱动

由于 Pentaho 在默认情况下，并不能直接和 SparkSQL 进行通信，但是它支持 Hadoop Hive2 的 JDBC 访问接口，所以用户只需要将 SparkSQL 的开发驱动拷贝一份到 Pentaho 解压目录下的 tomcat\lib 目录中即可。

```
cp /opt/spark/jars/hadoop-common-2.7.3.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/hive-exec-1.2.1.spark2.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/hive-jdbc-1.2.1.spark2.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/hive-metastore-1.2.1.spark2.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/httpclient-4.5.6.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/httpcore-4.4.10.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/libthrift-0.9.3.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/log4j-1.2.17.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/slf4j-api-1.7.16.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/slf4j-log4j12-1.7.16.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/spark-hive-thriftserver_2.11-2.4.4.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/spark-network-common_2.11-2.4.4.jar /opt/pentaho-server/tomcat/lib/
```

#### 修改 Pentaho 配置

1) Pentaho 依赖 Tomcat 提供服务，默认端口号为 8080，与 SparkSQL 服务页面冲突，因此需要修改端口号，这里修改为 8180。

```
sed -i 's/<Connector URIEncoding="UTF-8" port="8080"/<Connector URIEncoding="UTF-8" port="8180"/g' /opt/pentaho-server/tomcat/conf/server.xml
```

2) Pentaho 启动内存默认设置为 2G，在本次实验中适当调小。

```
sed -i "s/-Xms2048m -Xmx6144m -XX:MaxPermSize=256m/-Xms64m -Xmx256m -XX:MaxPermSize=64m/g" /opt/pentaho-server/start-pentaho.sh
```

#### 启动 Pentaho

配置好 Pentaho 后，用户只需要启动 Pentaho 即可正常使用。

```
/opt/pentaho-server/start-pentaho.sh
```

![1542-620-1](https://doc.shiyanlou.com/courses/1542/1207281/6ba27758f537c91f965b9e5ace205d30)

## Pentaho 的使用

#### 在 SparkSQL 中创建数据库

在 SparkSQL 中创建 sdb 数据库，用于连接测试。

```sql
CREATE DATABASE sdb ;
```

![1542-620-2](https://doc.shiyanlou.com/courses/1542/1207281/3ba8d1811c638e607991a03f9570bd64)

#### 登录 Pentaho

用户在按照以上步骤设置好 Pentaho 和 SequoiaDB 对接之后，就可以在浏览器上输入 http://localhost:8180 地址，登录到 Pentaho 的操作界面。

Pentaho 默认提供管理员账户及一般权限账户，并提供密码，第一次登录时以默认密码登录后可以在用户权限管理菜单中进行用户、角色的管理。本文以管理员账户 Admin 登录进行后续操作。

![1542-620-3](https://doc.shiyanlou.com/courses/1542/1207281/e016e98052b50d442c0bbb1f8c7bbbaa)

#### 新建数据库连接

用户在登录 Pentaho 的用户操作台后，在左上角点击“Manage Data Sources”，在弹出的对话框中选择新建连接。

![1542-620-4](https://doc.shiyanlou.com/courses/1542/1207281/e45e481f54394b2919bc667bcda11d46)

在弹出的窗口中，依次点击如下按钮，进入新建数据库连接页面。

![1542-620-5](https://doc.shiyanlou.com/courses/1542/1207281/d9913831f23ae84550c81e61ed7710f0)

在数据库类型框中选择 Hadoop Hive 2，接入方式选择 Native(JDBC)，并依次填入连接名称、主机名、数据库名、端口号、数据库用户、数据库密码。

![1542-620-6](https://doc.shiyanlou.com/courses/1542/1207281/62f6a0e3d6c970e0fb928b2818283ec0)

设置无误后点击测试，显示 Success 即表示配置成功。

![1542-620-7](https://doc.shiyanlou.com/courses/1542/1207281/07e5465ac57bde606d0f093fb7f409d4)

测试成功后，点击 OK，保存数据库连接配置即可正常使用。

![1542-620-8](https://doc.shiyanlou.com/courses/1542/1207281/c7d25191f5be22c36c5dac41a778be1d)

## 总结

通过本课程我们学习了如何在已经部署 SequoiaDB 巨杉数据库引擎及 SparkSQL 实例的环境中，进行 Pentaho 的安装，并进行 SparkSQL 的对接。

#### 知识点

+ Pentaho 的安装
+ Pentaho 与 SequoiaDB + SparkSQL 的对接
