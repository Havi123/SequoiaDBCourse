---
show: step
version: 1.0 
enable_checker: true 
---

# 图形化报表工具对接

## 试验介绍

本课程将带领您在已经部署 SequoiaDB 巨杉数据库引擎及 SparkSQL 实例的环境中，进行 Pentaho 的安装，并进行 SparkSQL 的对接。

#### 知识点

+ Pentaho 的安装
+ Pentaho 与 SequoiaDB + SparkSQL 的对接
+ 使用 Pentaho 制作简单折线图

## Pentaho 的安装部署

#### Pentaho 简介

Pentaho 分为商业版和社区版，社区版除了不包含商业版中特有的 Pentaho Analyzer、原厂专业支持服务、技术文档等，在其他绝大部分常用功能上，与商业版保持一致。本文以社区版 7.0 为例，演示 Pentaho 与 SequoiaDB + SparkSQL 对接及使用。

Pentaho社区版（7.0）下载地址为：

```html
https://sourceforge.net/projects/pentaho/files/Business%20Intelligence%20Server/7.0/pentaho-server-ce-7.0.0.0-25.zip
```
## 环境检查

#### 切换到 sdbadmin 用户

部署 SequoiaDB 巨杉数据库和 SequoiaSQL-MySQL 实例的操作系统用户为 sdbadmin。
```
su - sdbadmin
```
>Note:
>
>用户 sdbadmin 的密码为 sdbadmin

#### 查看巨杉数据库版本

查看 SequoiaDB 巨杉数据库引擎版本

```
sequoiadb --version
```
操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1469/1207281/b4082b0d6d6bdf89d229aa713a53759d)

## 查看节点启动列表

查看 SequoiaDB 巨杉数据库引擎节点列表

```
sdblist 
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1469/1207281/02fcaa58ac27e91688ead137fa748d6e)

>Note:
>
>如果显示的节点数量与预期不符，请稍等初始化完成并重试该步骤


## Spark 进程检查
查看 Spark 的 Worker 和 Master 是否已经启动
```
jps
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1469/1207281/02fcaa58ac27e91688ead137fa748d6e)

>Note:
>
>如果显示的进程名称和数量与预期不符，请稍等初始化完成并重试该步骤

## Pentaho 的安装

Pentaho 下载得到的安装文件为 pentaho-server-ce-7.0.0.0-25.zip。社区版 Pentaho 安装仅需要解压安装文件到指定目录即可，适用于 Windows 和 Linux 环境。

解压 Pentaho 安装包

```
unzip /home/sdbadmin/soft/pentaho-server-ce-7.0.0.0-25.zip -d /opt
```





## Pentaho 对接 SequoiaDB + Spark SQL

#### 配置 SparkSQL 驱动

由于 Pentaho 在默认情况下，并不能直接和 SparkSQL 进行通信，但是它支持 Hadoop Hive2 的 JDBC 访问接口，所以用户只需要将 SparkSQL 的开发驱动拷贝一份到 Pentaho 解压目录下的 tomcat\lib 目录中即可。

```
cp /opt/spark/jars/hadoop-common-2.7.3.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/hive-exec-1.2.1.spark2.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/hive-jdbc-1.2.1.spark2.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/hive-metastore-1.2.1.spark2.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/httpclient-4.5.6.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/httpcore-4.4.10.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/libthrift-0.9.3.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/log4j-1.2.17.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/slf4j-api-1.7.16.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/slf4j-log4j12-1.7.16.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/spark-hive-thriftserver_2.11-2.4.4.jar /opt/pentaho-server/tomcat/lib/
cp /opt/spark/jars/spark-network-common_2.11-2.4.4.jar /opt/pentaho-server/tomcat/lib/
```

#### 修改 Pentaho 配置

1）Pentaho 依赖 Tomcat 提供服务，默认端口号为 8080，与 SparkSQL 服务页面冲突，因此需要修改端口号，这里修改为 8180；

```
sed -i 's/<Connector URIEncoding="UTF-8" port="8080"/<Connector URIEncoding="UTF-8" port="8180"/g' /opt/pentaho-server/tomcat/conf/server.xml
```

2）Pentaho 启动内存默认设置为 2G，在本次实验中适当调小；

```
sed -i "s/-Xms2048m -Xmx6144m -XX:MaxPermSize=256m/-Xms128m -Xmx256m -XX:MaxPermSize=128m/g" /opt/pentaho-server/start-pentaho.sh
```

#### 启动 Pentaho

配置好 Pentaho 后，用户只需要启动 Pentaho 即可正常使用。

```
/opt/pentaho-server/start-pentaho.sh
```

![1542-620-1](https://doc.shiyanlou.com/courses/1542/1207281/6ba27758f537c91f965b9e5ace205d30)

## Pentaho 的使用

#### 在 SparkSQL 中创建数据库

1）登录 Beeline 客户端连接 SparkSQL 实例；

```
/opt/spark-2.4.4-bin-hadoop2.7/bin/beeline -u 'jdbc:hive2://localhost:10000'
```

2）在 SparkSQL 中创建 sdb 数据库，用于连接测试。

```
create database company ;
```



![1542-620-2](https://doc.shiyanlou.com/courses/1542/1207281/3ba8d1811c638e607991a03f9570bd64)


3）退出 Beeline 客户端；
```
!quit
```


#### 登录 Pentaho

用户在按照以上步骤设置好 Pentaho 和 SequoiaDB 对接之后，就可以在浏览器上输入 http://localhost:8180 地址，登录到 Pentaho 的操作界面。

Pentaho 默认提供管理员账户及一般权限账户，并提供密码，第一次登录时以默认密码登录后可以在用户权限管理菜单中进行用户、角色的管理。本文以管理员账户 Admin 登录进行后续操作。

![1542-620-3](https://doc.shiyanlou.com/courses/1542/1207281/e016e98052b50d442c0bbb1f8c7bbbaa)

#### 新建数据库连接

1）用户在登录 Pentaho 的用户操作台后，在左上角点击“Manage Data Sources”，在弹出的对话框中选择新建连接；

![1542-620-4](https://doc.shiyanlou.com/courses/1542/1207281/e45e481f54394b2919bc667bcda11d46)

2）在弹出的窗口中，依次点击如下按钮，进入新建数据库连接页面；

![1542-620-5](https://doc.shiyanlou.com/courses/1542/1207281/d9913831f23ae84550c81e61ed7710f0)

3）在数据库类型框中选择 Hadoop Hive 2，接入方式选择 Native(JDBC)，并依次填入连接名称、主机名、数据库名、端口号、数据库用户、数据库密码；

![1542-620-6](https://doc.shiyanlou.com/courses/1542/1207281/62f6a0e3d6c970e0fb928b2818283ec0)

4）设置无误后点击测试，显示 Success 即表示配置成功；

![1542-620-7](https://doc.shiyanlou.com/courses/1542/1207281/07e5465ac57bde606d0f093fb7f409d4)

5）测试成功后，点击 OK，保存数据库连接配置即可正常使用；

![1542-620-8](https://doc.shiyanlou.com/courses/1542/1207281/c7d25191f5be22c36c5dac41a778be1d)

## 制作一个简单的折线图
本章节将在 SequoiaDB 巨杉数据库引擎中创建集合空间和集合，并在 SparkSQL 中创建对饮的映射表，为折线图提供基础数据。
#### 初始化数据

1）使用 Linux 命令进入 SequoiaDB Shell 命令行；

```
sdb
```

2）连接 SequoiaDB 数据库；

```javascript
db = new Sdb ("localhost", 11810) ;
```

3）创建 company_domain 逻辑域；

```javascript
db.createDomain ( "company_domain", ["group1", "group2", "group3"], { AutoSplit : true } ) ;
```

4）创建 company 集合空间；

```javascript
db.createCS ( "company", {Domain: "company_domain"} ) ;
```

5）创建 employee 集合；

```javascript
db.company.createCL ( "employee", { "ShardingKey" : { "_id" : 1} , "ShardingType" : "hash" , "ReplSize" : -1 , "Compressed" : true , "CompressionType" : "lzw" , "AutoSplit" : true , "EnsureShardingIndex" : false } ) ;
```

![1542-620-9](https://doc.shiyanlou.com/courses/1542/1207281/40adffe06ee40e5433ad4f01ebed6097)

6）登录 Beeline 客户端连接 SparkSQL 实例；

```
/opt/spark-2.4.4-bin-hadoop2.7/bin/beeline -u 'jdbc:hive2://localhost:10000'
```

7）创建 employee 表

创建 employee 表，并且与 SequoiaDB 中的集合 company.employee 进行关联；

```sql
CREATE TABLE company.employee (
  empno  INT,
  ename  VARCHAR(128),
  age    INT
) USING com.sequoiadb.spark OPTIONS (
  host 'localhost:11810',
  collectionspace 'company',
  collection 'employee'
) ;
```

8）向 employee 表中插入数据

```sql
INSERT INTO company.employee VALUES (10001, 'Georgi', 48), 
                            (10002, 'Bezalel', 21), 
                            (10003, 'Parto', 33), 
                            (10004, 'Chirstian', 40),
                            (10005, 'Kyoichi', 23), 
                            (10006, 'Anneke', 19), 
                            (10007, 'Ileana', 28), 
                            (10008, 'Liz', 38), 
                            (10009, 'Parish', 31), 
                            (10010, 'Odette', 23) ;
```

![1542-620-10](https://doc.shiyanlou.com/courses/1542/1207281/ee8efb16b0d4e82796d9c7a3a84feb5e)

#### 统计口径

1）查询所有人员的年龄作为纵坐标；

```sql
SELECT DISTINCT age FROM company.employee ORDER BY age
```

2）查询所有人员的名字、年龄数据，并将名字作为横坐标；

```sql
SELECT ename, age FROM company.employee ORDER BY empno
```

#### 创建数据源

1）依次点击 Pentaho 首页的 Create New > CDE Dashboard 按钮；

![1542-620-11](https://doc.shiyanlou.com/courses/1542/1207281/c7be3e8a8f4ebd765f0d012c8dd9fac4)

2）点击如图所示按钮，进入数据源设置页面；

![1542-620-12](https://doc.shiyanlou.com/courses/1542/1207281/f749269c99e5febb011ecc3b88b61ac2)

3）点击如图所示按钮，添加两个数据源配置项；

![1542-620-13](https://doc.shiyanlou.com/courses/1542/1207281/91bb8a931b49dfc9d69c09823872d923)

4）在第一个数据源的 Query 配置项中加入查询年份的 SQL,其它配置如图所示；

![1542-620-14](https://doc.shiyanlou.com/courses/1542/1207281/edc4487d48f39af42baf1c130a2a1f5f)

5）在第二个数据源的 Query 配置项中加入查询所有人员名字、年龄的 SQL，其他配置如图所示；

![1542-620-15](https://doc.shiyanlou.com/courses/1542/1207281/460c680b9fda775bdbf45805a2f833eb)

6）点击 Save 按钮，将新建的仪表盘命名为DEMO并保存；

![1542-620-16](https://doc.shiyanlou.com/courses/1542/1207281/9b77783d2ed65f6579eea40bcb2dd5f3)

#### 调整布局

1）保存完毕之后，切换到布局面板，对报表的整体显示布局进行设置。首先点击如图所示按钮，选择图表模板；

![1542-620-17](https://doc.shiyanlou.com/courses/1542/1207281/0174f8d75165d120e5635dada44119db)

2）选择自己喜欢的模板后，在如下图所示的 Body 标签下，选择居中的 Column 标签；

![1542-620-18](https://doc.shiyanlou.com/courses/1542/1207281/da1288662f6dfe19b88f699eaea37f10)

3）点击下图所示工具栏的两个按钮，在选中标签下添加标签，添加完成后，如下图所示；

![1542-620-19](https://doc.shiyanlou.com/courses/1542/1207281/40328fd8d8e4c7033f792f05d445ea58)

4）在新建的两个 Cloumn 标签中设置属性，如下图所示；

![1542-620-20](https://doc.shiyanlou.com/courses/1542/1207281/7d00ba331060e74b8d0154da14d36ed0)

5）点击 Save 按钮,进行保存；

#### 添加组件

1）保存成功后，切换到添加组件页面，按钮位置如下图所示

![1542-620-21](https://doc.shiyanlou.com/courses/1542/1207281/62f282520f2f2b5d2b7613ca7727ea2c)

2）依次点击以下按钮，添加折线图纵坐标组件，并将属性设置为下图所示内容；

![1542-620-22](https://doc.shiyanlou.com/courses/1542/1207281/6596a3f6992f521939a1f67df2287f78)

3）依次点击以下按钮，添加折线图横坐标组件，并将属性设置为下图所示内容；

![1542-620-23](https://doc.shiyanlou.com/courses/1542/1207281/ff7581b4f054817bac7dadb610103c1a)

4）点击 Save 按钮,进行保存；

#### 查看折线图

1）依次点击下图所示按钮，进入文件展示选择页面；

![1542-620-24](https://doc.shiyanlou.com/courses/1542/1207281/a6497efa01d3b8bf5c17a1339ba8dd88)

2）选择制作好的折线图文件；

![1542-620-25](https://doc.shiyanlou.com/courses/1542/1207281/030d0463a75e5271cd1e049177fce141)

3）双击之后，就可以展示出制作好的折线图了，如果对制作结果满意，也可以重新修改图示等进行美化；

![1542-620-25](https://doc.shiyanlou.com/courses/1542/1207281/6550be03b6e0103da76402050bf21617)

## 总结

通过本课程我们学习了如何在已经部署 SequoiaDB 巨杉数据库引擎及 SparkSQL 实例的环境中，进行 Pentaho 的安装，并进行 SparkSQL 的对接。

#### 知识点


+ Pentaho 的安装
+ Pentaho 与 SequoiaDB + SparkSQL 的对接
+ 使用 Pentaho 制作简单折线图

