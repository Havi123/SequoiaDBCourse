---
show: step
version: 18.0 
enable_checker: true 
---

# 对在线联机业务零干扰进行后台统计分析

## 课程介绍

本课程将带领您在已经部署 SequoiaDB 巨杉数据库引擎及创建了 MySQL 实例、SparkSQL 实例的环境中，通过配置协调节点的读写分离策略，实现在线联机业务与后台统计分析业务的相互隔离。

#### SequoiaDB 巨杉数据库读写分离介绍

1）写请求处理

所有写请求都只会发往主节点，如果没有主节点则当前复制组不可处理写请求。

2）读请求处理

读请求会按照会话（连接）随机选择组内任意一个节点（对外透明），或按照当前会话（连接）配置的优先实例策略选取相应复制组的数据节点。在一次会话中如果上一次查询（包括 query 和 fetch）返回成功，则下一次查询不会重选节点；如果上一次查询发生失败，则下一次查询将重选节点。如果没有可用节点则返回失败。一次查询中不会重选节点。


#### 请点击右侧选择使用的实验环境

#### 部署架构：

本课程中 SequoiaDB 巨杉数据库的集群拓扑结构为一分区三副本，其中，SQL 引擎包括 1 个 SequoiaSQL-MySQL 数据库实例节点和 1 个 SparkSQL 实例节点，数据库引擎包括 3 个协调节点、3 个编目节点和3个数据节点。

![图片描述](https://doc.shiyanlou.com/courses/1542/1207281/962be24a5948c3b6563bbfd480b5020f-0)

详细了解 SequoiaDB 巨杉数据库系统架构：

* [SequoiaDB 系统架构](http://doc.sequoiadb.com/cn/sequoiadb-cat_id-1519649201-edition_id-0)


#### 实验环境

课程使用的实验环境为 Ubuntu Linux 16.04 64 位版本；SequoiaDB 巨杉数据库引擎以及 SequoiaSQL-MySQL 实例和  SequoiaDB-SparkSQL 实例连接器均为 3.4 版本；Spark 版本为2.4.4；JDK 版本为 openjdk1.8。

## 切换用户及查看数据库版本

切换到系统用户 sdbadmin，并查看 SequoiaDB 巨杉数据库引擎的版本。

#### 切换到 sdbadmin 用户

部署 SequoiaDB 巨杉数据库和 SequoiaSQL-MySQL 实例的操作系统用户为 sdbadmin。

```shell
su - sdbadmin
```

>Note:
>
>用户 sdbadmin 的密码为 `sdbadmin` 。

#### 查看巨杉数据库版本

查看 SequoiaDB 巨杉数据库引擎版本：

```shell
sequoiadb --version
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1469/1207281/b4082b0d6d6bdf89d229aa713a53759d)

## 查看节点启动列表

查看 SequoiaDB 巨杉数据库引擎节点列表：

```shell
sdblist
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1542/1207281/40c34595a78027ff3c0d16c9d3bb1e17-0)

>Note:
>
>如果显示的节点数量与预期不符，请稍等初始化完成并重试该步骤。

## 初始化数据

创建 SequoiaDB 集合空间和集合与 SparkSQL 进行关联，并插入部分记录作为后续的实验数据。

#### 创建数据库和数据表 

进入 MySQL Shell，在 MySQL 实例中创建数据库 company，以及 employee 表。

1）使用 Linux 命令进入 MySQL Shell；

```shell
/opt/sequoiasql/mysql/bin/mysql -h 127.0.0.1 -P 3306 -u root
```

操作截图：

![1542-1](https://doc.shiyanlou.com/courses/1542/1207281/7d8844ea1e16999906e9751569285b9f-0)

2）创建 company 数据库；

```sql
CREATE DATABASE company ;
```

操作截图：

![1542-2](https://doc.shiyanlou.com/courses/1542/1207281/da4dfc02f535fb6d0e35036230234ea0)

3）切换到 company 数据库；

```sql
USE company ;
```

操作截图：

![1542-3](https://doc.shiyanlou.com/courses/1542/1207281/c2c87510e14c17629134ae4ea811df05-0)

4）创建 employee 表，将同步在 SequoiaDB 巨杉数据引擎中创建分区表；

```sql
CREATE TABLE employee (
    empno INT AUTO_INCREMENT PRIMARY KEY,
    ename VARCHAR(128),
    age INT
) ;
```

操作截图：

![1542-4](https://doc.shiyanlou.com/courses/1542/1207281/4fbd9991416f14e1039e5e0edc98d93f-0)

5）向 employee 表中写入数据；

```sql
INSERT INTO employee VALUES ( 10001, 'Georgi', 48 ),
                            ( 10002, 'Bezalel', 21 ),
                            ( 10003, 'Parto', 33 ),
                            ( 10004, 'Chirstian', 40 ),
                            ( 10005, 'Kyoichi', 23 ),
                            ( 10006, 'Anneke', 19 ),
                            ( 10007, 'Ileana', 28 ),
                            ( 10008, 'Liz', 38 ),
                            ( 10009, 'Parish', 31 ),
                            ( 10010, 'Odette', 23 ) ;
```

6）退出 MySQL Shell；

```shell
\q
```

## 选取优先读备的协调节点

给 SparkSQL 配置一个专用的协调节点进行数据访问，使用该协调节点进行统计分析查询。

1）在 Linux Shell 查看当前集群中的协调节点；

```shell
sdblist -l | grep -E "Name|coord"
```

操作截图：

![1542-7](https://doc.shiyanlou.com/courses/1542/1207281/c2d1c7741a35645bbf58372cb0ef2a42-0)

2）查看 MySQL 实例使用的协调节点；

```shell
/opt/sequoiasql/mysql/bin/mysql -h 127.0.0.1 -P 3306 -u root -e "SHOW VARIABLES LIKE 'sequoiadb_conn%';"
```

操作截图：

![1542-8](https://doc.shiyanlou.com/courses/1542/1207281/4380d93b34f05fe22f8c68761e0c0321-0)

发现集群中有协调节点 11810、21810、31810 三个，MySQL 实例使用 11810 节点，于是在创建 SparkSQL 表时配置专用协调节点 21810。

## 在 SparkSQL 中建表

进入 SparkSQL Beeline Shell，在 SparkSQL 实例中创建 employee 表并与 SequoiaDB 中的集合空间、集合关联。

1）查看 Spark 的 Worker 和 Master 是否已经启动；

```shell
jps
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1542/1207281/08b13cea5b24b82255bc9a9289de13df-0)

>Note:
>
>如果显示的进程名称与预期不符，请稍等初始化完成并重试该步骤。

2）登录 Beeline 连接到 SparkSQL 实例；

```shell
/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000'
```

操作截图：

![1542-10](https://doc.shiyanlou.com/courses/1542/1207281/6c2037a0c2378e76bb410347e00a6275)

3）创建 employee 表；

创建 employee 表，并且与 SequoiaDB 中的集合 company.employee 进行关联；

```sql
CREATE TABLE employee (
  empno  INT,
  ename  VARCHAR(128),
  age    INT
) USING com.sequoiadb.spark OPTIONS (
  host 'localhost:21810',
  collectionspace 'company',
  collection 'employee',
  preferredinstance 'S',
  preferredinstancemode 'random',
  preferredinstancestrict true
) ;
```

>Note:
>
> 通过指定 `host` 可以限定查询连接的协调节点，设置 `preferredinstance` 参数为 "S" 表示查询时优先读取备数据节点的数据，更详细的参数配置可参考 [SequoiaDB-SparkSQL 参数说明](http://doc.sequoiadb.com/cn/sequoiadb-cat_id-1432190712-edition_id-304)。

4）退出 Beeline Shell；

```shell
!quit
```

操作截图：

![1542-11](https://doc.shiyanlou.com/courses/1542/1207281/102bc1a7f7dcff9a04d7b5b2aba8fd68-0)

## 确定数据组 group1 主节点

使用 SequoiaDB 的系统命令 sdblist 确定数据组 group1 的主节点，以便确认联机交易跟统计分析是否在同数据组的不同数据节点上执行。

在 Linux Shell 中执行以下命令，确认数据组 group1 的主节点；

```shell
sdblist -l | grep -E "Name|group1"
```

操作截图：

![1542-6](https://doc.shiyanlou.com/courses/1542/1207281/aa55a5d531f21a0a80385b22e2b044f4-0)

从查询结果可以看出，数据组 group1 中，31820 节点是主节点，11820、21820 两个节点是备节点。

## 验证联机业务与统计分析的相互隔离

分别在 MySQL 端、SparkSQL 端进行对表 employee 的查询操作，会发现在不同的 SQL 实例上进行查询，在同数据组内，会从不同的数据节点上进行数据读取。下面以数据组 group1 为例进行验证。

#### 检查数据组 group1 各数据节点的数据读取量

1）使用嵌入命令模式连接 SequoiaDB 巨杉数据库协调节点；

```shell
sdb 'db = new Sdb ( "localhost", 11810 )'
```

2）使用 snapshot ( 4 ) 查询集合 company.employee 在数据组 group1 各数据节点的数据读取量；

```shell
sdb 'db.snapshot( 4, { Name : "company.employee" } )' | grep -E "NodeName|TotalDataRead|GroupName"
```

操作截图：

![1542-12](https://doc.shiyanlou.com/courses/1542/1207281/38929968ea0ba0ba95953f6bfe9922fd-0)

#### 在 MySQL 端查询 employee 表并观察数据读取状况

1）使用 Linux 命令进入 MySQL Shell；

```shell
/opt/sequoiasql/mysql/bin/mysql -h 127.0.0.1 -P 3306 -u root
```

2）对 employee 表进行全表查询；

```sql
SELECT * FROM company.employee ;
```

3）退出 MySQL Shell；

```shell
\q
```

操作截图：

![1542-13](https://doc.shiyanlou.com/courses/1542/1207281/5488d39a9cc9b782e689a5f663cce6ff)

4）使用 snapshot ( 4 ) 查询集合 company.employee 在数据组 group1 各数据节点的数据读取量；

```shell
sdb 'db.snapshot( 4, { Name : "company.employee" } )' | grep -E "NodeName|TotalDataRead|GroupName"
```

操作截图：

![1542-14](https://doc.shiyanlou.com/courses/1542/1207281/71a7e3c1e1ae732876a258728e794148-0)

从查询结果可以看出，MySQL 实例上的查询，在数据组 group1 中，主节点 31820 上的数据查询量增加了，备节点 11820、21820 两个节点上的查询量未增加。

#### 在 SparkSQL 端查询 employee 表并观察数据读取状况

1）登录 Beeline 连接到 SparkSQL 实例；

```shell
/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000'
```

2）对 employee 表进行全表查询；

```sql
SELECT * FROM employee ;
```

3）退出 Beeline Shell；

```shell
!quit
```

操作截图：

![1542-15](https://doc.shiyanlou.com/courses/1542/1207281/a16fb8d3cf373d34fa9d689395129959)

4）使用 snapshot ( 4 ) 查询集合 company.employee 在数据组 group1 各数据节点的数据读取量；

```shell
sdb 'db.snapshot( 4, { Name : "company.employee" } )' | grep -E "NodeName|TotalDataRead|GroupName"
```

操作截图：

![1542-16](https://doc.shiyanlou.com/courses/1542/1207281/17f368a2b645a17c37f19e3d6a4fcea0-0)

从查询结果可以看出，SparkSQL 实例上的查询，在数据组 group1 中，主节点 31820 上的数据查询量没有增加，备节点 21820 上的查询量增加。

>Note:
>
> 本环境中数据节点采用三副本架构，包括一个主节点和两个备节点；配置优先从备节点中读取数据，会在两个可选备节点中随机选取其中一个，所以从 SaprkSQL 实例上的查询，数据查询量增加的不一定是 21820 还可能是 11820。

## 总结

通过本课程，我们学习了如何配置读写分离策略，保证在线联机业务与后台统计分析的相互隔离，并且学习了如何在 MySQL 实例、SparkSQL 实例中操作 SeuqoiaDB 巨杉数据库中的数据。

今天我们学到的知识点为：

+ MySQL 的使用
+ SparkSQL 的使用
+ SequoiaDB 读写分离策略的配置
+ 联机业务与统计分析的相互隔离
