---
show: step
version: 1.0 
enable_checker: true 
---

# 对在线联机业务零干扰进行后台统计分析

## 试验介绍

本课程将带领您在已经部署 SequoiaDB 巨杉数据库引擎及创建了 MySQL 实例、SparkSQL 实例的环境中，通过配置协调节点的读写分离策略，实现在线联机业务与后台统计分析业务的相互隔离。其中SequoiaSQL-SparkSQL 数据库实例包括2个worker节点，SequoiaDB 巨杉数据库包括1个引擎协调组，1个编目组与3个数据组。

#### 知识点

+ MySQL 的使用
+ SparkSQL 的使用
+ SequoiaDB 读写分离策略的配置
+ 联机业务与统计分析的相互隔离

## 初始化数据

#### 请点击右侧选择使用的实验环境

#### 在 MySQL 中创建数据库、表

进入 MySQL Shell，在 MySQL 中创建数据库 company，以及 employee 表。

1) 使用 Linux 命令进入 MySQL shell

```
mysql -h 127.0.0.1 -u root
```

![1542-1](https://doc.shiyanlou.com/courses/1542/1207281/016331e2eaa1f19547f5e29bde855db2)

2) 创建 company 数据库

```sql
CREATE DATABASE company ;
```

![1542-2](https://doc.shiyanlou.com/courses/1542/1207281/da4dfc02f535fb6d0e35036230234ea0)

3) 切换到 company 数据库
```sql
USE company ;
```

![1542-3](https://doc.shiyanlou.com/courses/1542/1207281/c7b500ec2d5bbe147a5402dedc5f5e2a)

4) 创建 employee 表

```sql
CREATE TABLE employee (
  empno  INT,
  ename  VARCHAR(128),
  age    INT,
  PRIMARY KEY (empno)
) ENGINE = SequoiaDB ; 
```

![1542-4](https://doc.shiyanlou.com/courses/1542/1207281/6300ee12a1d55029e05b8ea187877b72)

#### 在 MySQL 中插入数据

向 employee 表中插入数据

```sql
INSERT INTO employee VALUES (10001, 'Georgi', 48), 
                            (10002, 'Bezalel', 21), 
                            (10003, 'Parto', 33), 
                            (10004, 'Chirstian', 40),
                            (10005, 'Kyoichi', 23), 
                            (10006, 'Anneke', 19), 
                            (10007, 'Ileana', 28), 
                            (10008, 'Liz', 38), 
                            (10009, 'Parish', 31), 
                            (10010, 'Odette', 23) ;
```

![1542-5](https://doc.shiyanlou.com/courses/1542/1207281/af7873bbffc4f1032c957b7561c2d84d)

#### 在 SparkSQL 中创建数据库、表


## 确定数据组 group1 主节点

使用 SequoiaDB 的系统命令 sdblist 确定数据组 group1 的主节点，以便确认联机交易跟统计分析是否在同数据组的不同数据节点上执行。

在 Linux Shell 中执行以下命令，确认数据组 group1 的主节点

```
sdblist -l | grep -E "Name|group1"
``` 

![1542-6](https://doc.shiyanlou.com/courses/1542/1207281/6a6ee724a83df813b2c0eb71b373b452)

从查询结果可以看出，数据组 group1 中，11820 节点是主节点，21820、31820 两个节点是备节点。

## 在 SparkSQL 中配置读写分离

给 SparkSQL 配置一个专用的协调节点进行数据访问，在该协调节点上进行读写分离配置。

#### 给专用协调节点配置读写分离

1) 查看当前集群中的协调节点

```
sdblist -l | grep -E "Name|coord"
```

![1542-7](https://doc.shiyanlou.com/courses/1542/1207281/04c82ea17c29efd19adb797be2595750)

2) 查看 MySQL 实例使用的协调节点

```sql
show variables like 'sequoiadb_conn%';
```

![1542-8](https://doc.shiyanlou.com/courses/1542/1207281/4e31f837f4bd6c7b284d1bc53597d413)

发现集群中有协调节点 11810、21810、31810 三个，MySQL 实例使用 11810 节点，于是给 SparkSQL 配置专用协调节点 21810。

3) 给协调节点 21810 设置读写分离

1) 连接 SequoiaDB

```
sdb 'db = new Sdb("localhost", 11810)'
```

2) 给协调节点 21810 设置读写分离

```
sdb 'db.updateConf({preferredinstance: "A"}, {NodeName: "sdbserver1:21810"})'
```

![1542-9](https://doc.shiyanlou.com/courses/1542/1207281/33fc1ca7511c504bb1d9736d6abba1e2)

#### 在 SparkSQL 中建表 

进入 SparkSQL Beeline Shell，在 SparkSQL 实例中创建 employee 表并与 SequoiaDB 中的集合空间、集合关联。

1) 登录到 SparkSQL 实例 Beeline Shell

```
/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000'
```

![1542-10](https://doc.shiyanlou.com/courses/1542/1207281/6c2037a0c2378e76bb410347e00a6275)

2) 创建 employee 表

创建 employee 表，并且与 SequoiaDB 中的集合 company.employee 进行关联

```sql
CREATE TABLE employee (
  empno  INT,
  ename  VARCHAR(128),
  age    INT
) USING com.sequoiadb.spark OPTIONS (
  host 'localhost:21810',
  collectionspace 'company',
  collection 'employee'
) ;
```

![1542-11](https://doc.shiyanlou.com/courses/1542/1207281/beac9efc306ce29a870fbcee7db94161)

## 验证联机业务与统计分析的相互隔离

分别在 MySQL 端、SparkSQL 端进行对表 employee 的查询操作，会发现在不同的 SQL 实例上进行查询，在同数据组内，会从不同的数据节点上进行数据读取。下面以数据组 group1 为例进行验证。

#### 检查数据组 group1 各数据节点的数据读取量

使用 snapshot(4) 查询集合 company.employee 在数据组 group1 各数据节点的数据读取量

```
sdb 'db.snapshot(4, {Name: "company.employee"})' | grep -E "NodeName|TotalDataRead|GroupName"
```

![1542-12](https://doc.shiyanlou.com/courses/1542/1207281/7a0fa7c9dd0484517ce818fec1e8b074)

#### 在 MySQL 端查询 employee 表并观察数据读取状况

1) 对 employee 表进行全表查询

```sql
SELECT * FROM company.employee ;
```

![1542-13](https://doc.shiyanlou.com/courses/1542/1207281/5488d39a9cc9b782e689a5f663cce6ff)

2) 使用 snapshot(4) 查询集合 company.employee 在数据组 group1 各数据节点的数据读取量

```
sdb 'db.snapshot(4, {Name: "company.employee"})' | grep -E "NodeName|TotalDataRead|GroupName"
```

![1542-14](https://doc.shiyanlou.com/courses/1542/1207281/2c34a1e9602f6754cc40320ee3075149)

从查询结果可以看出，MySQL 实例上的查询，在数据组 group1 中，主节点 11820 上的数据查询量增加了，备节点 21820、31820 两个节点上的查询量未增加。

#### 在 SparkSQL 端查询 employee 表并观察数据读取状况

1) 对 employee 表进行全表查询

```sql
SELECT * FROM employee ;
```

![1542-15](https://doc.shiyanlou.com/courses/1542/1207281/a16fb8d3cf373d34fa9d689395129959)

2) 使用 snapshot(4) 查询集合 company.employee 在数据组 group1 各数据节点的数据读取量

```
sdb 'db.snapshot(4, {Name: "company.employee"})' | grep -E "NodeName|TotalDataRead|GroupName"
```

![1542-16](https://doc.shiyanlou.com/courses/1542/1207281/e3fe22afded71f502c094fd6829bc9d1)

从查询结果可以看出，SparkSQL 实例上的查询，在数据组 group1 中，主节点 11820 上的数据查询量没有增加，备节点 31820 上的查询量增加。

## 总结

通过本课程，我们学习了如何配置读写分离策略，保证在线联机业务与后台统计分析的相互隔离，并且学习了如何在 MySQL、SparkSQL 中操作 SeuqoiaDB 数据库中的数据。

今天我们学到的知识点为：

+ MySQL 的使用
+ SparkSQL 的使用
+ SequoiaDB 读写分离策略的配置
+ 联机业务与统计分析的相互隔离
