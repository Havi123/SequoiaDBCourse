---
show: step
version: 4.0 
enable_checker: true 
---

# 对在线联机业务零干扰进行后台统计分析

## 课程介绍

本课程将带领您在已经部署 SequoiaDB 巨杉数据库引擎及创建了 MySQL 实例、SparkSQL 实例的环境中，通过配置协调节点的读写分离策略，实现在线联机业务与后台统计分析业务的相互隔离。

#### 请点击右侧选择使用的实验环境

#### 部署架构：

本课程中 SequoiaDB 巨杉数据库的集群拓扑结构为三分区三副本，其中包括 1 个引擎协调节点，1 个编目节点与 3 个数据组。 部署了 1 个 SequoiaSQL-MySQL 数据库实例节点，1 个 SequoiaSQL-SparkSQL 数据库实例，其中 SequoiaSQL-SparkSQL 实例包括 2 个 worker 节点。

![图片描述](https://doc.shiyanlou.com/courses/1542/1207281/014346f91e791723c901eeb103554319-0)

详细了解 SequoiaDB 巨杉数据库系统架构：
* [SequoiaDB 系统架构](http://doc.sequoiadb.com/cn/sequoiadb-cat_id-1519649201-edition_id-0)

#### SequoiaDB 巨杉数据库读写分离介绍

1）写请求处理

所有写请求都只会发往主节点，如果没有主节点则当前复制组不可处理写请求。

2）读请求处理

读请求会按照会话（连接）随机选择组内任意一个节点（对外透明），或按照当前会话（连接）配置的优先实例策略选取相应复制组的数据节点。在一次会话中如果上一次查询（包括 query 和 fetch）返回成功，则下一次查询不会重选节点；如果上一次查询发生失败，则下一次查询将重选节点。如果没有可用节点则返回失败。一次查询中不会重选节点。

#### 知识点

+ MySQL 的使用
+ SparkSQL 的使用
+ SequoiaDB 读写分离策略的配置
+ 联机业务与统计分析的相互隔离

#### 实验环境

课程使用的实验环境为 Ubuntu Linux 16.04 64 位版本。SequoiaDB 数据库引擎以及 SequoiaSQL-MySQL 实例均为 3.4 版本。

## 切换用户及查看数据库版本

#### 切换到 sdbadmin 用户

部署 SequoiaDB 巨杉数据库和 SequoiaSQL-MySQL 实例的操作系统用户为 sdbadmin。

```shell
su - sdbadmin
```

>Note:
>
>用户 sdbadmin 的密码为 `sdbadmin` 。

#### 查看巨杉数据库版本

查看 SequoiaDB 巨杉数据库引擎版本；

```shell
sequoiadb --version
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1469/1207281/b4082b0d6d6bdf89d229aa713a53759d)

## 查看节点启动列表

查看 SequoiaDB 巨杉数据库引擎节点列表；

```shell
sdblist
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1542/1207281/0cc9d31e0f4856d8031c1b9e863285b4-0)

>Note:
>
>如果显示的节点数量与预期不符，请稍等初始化完成并重试该步骤。

## Spark 进程检查

查看 Spark 的 Worker 和 Master 是否已经启动；

```shell
jps
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1542/1207281/08b13cea5b24b82255bc9a9289de13df-0)

>Note:
>
>如果显示的进程名称与预期不符，请稍等初始化完成并重试该步骤。

## 初始化数据

#### 创建数据库和数据表 

进入 MySQL Shell，在 MySQL 实例中创建数据库 company，以及 employee 表。

1）使用 Linux 命令进入 MySQL shell；

```shell
/opt/sequoiasql/mysql/bin/mysql -h 127.0.0.1 -P 3306 -u root
```

操作截图：

![1542-1](https://doc.shiyanlou.com/courses/1542/1207281/7d8844ea1e16999906e9751569285b9f-0)

2）创建 company 数据库；

```sql
CREATE DATABASE company ;
```

操作截图：

![1542-2](https://doc.shiyanlou.com/courses/1542/1207281/da4dfc02f535fb6d0e35036230234ea0)

3）切换到 company 数据库；

```sql
USE company ;
```

操作截图：

![1542-3](https://doc.shiyanlou.com/courses/1542/1207281/c7b500ec2d5bbe147a5402dedc5f5e2a)

4）创建 employee 表，将同步在 SequoiaDB 巨杉数据引擎中创建分区表；

```sql
CREATE TABLE employee (
    empno INT AUTO_INCREMENT PRIMARY KEY,
    ename VARCHAR(128),
    age INT
) ;
```

操作截图：

![1542-4](https://doc.shiyanlou.com/courses/1542/1207281/4fbd9991416f14e1039e5e0edc98d93f-0)

5）向 employee 表中写入数据；

```sql
INSERT INTO employee VALUES (10001, 'Georgi', 48),
                            (10002, 'Bezalel', 21),
                            (10003, 'Parto', 33),
                            (10004, 'Chirstian', 40),
                            (10005, 'Kyoichi', 23),
                            (10006, 'Anneke', 19),
                            (10007, 'Ileana', 28),
                            (10008, 'Liz', 38),
                            (10009, 'Parish', 31),
                            (10010, 'Odette', 23) ;
```

## 配置读写分离

给 SparkSQL 配置一个专用的协调节点进行数据访问，在该协调节点上进行读写分离配置。

#### 给专用协调节点配置读写分离

1）查看当前集群中的协调节点；

```shell
sdblist -l | grep -E "Name|coord"
```

操作截图：

![1542-7](https://doc.shiyanlou.com/courses/1542/1207281/c2d1c7741a35645bbf58372cb0ef2a42-0)

2）查看 MySQL 实例使用的协调节点；

```sql
SHOW VARIABLES LIKE 'sequoiadb_conn%';
```

操作截图：

![1542-8](https://doc.shiyanlou.com/courses/1542/1207281/4e31f837f4bd6c7b284d1bc53597d413)

发现集群中有协调节点 11810、21810、31810 三个，MySQL 实例使用 11810 节点，于是给 SparkSQL 配置专用协调节点 21810。

3）给协调节点设置读写分离；

1. 使用嵌入命令模式连接 SequoiaDB 巨杉数据库协调节点；

```shell
sdb 'var db = new Sdb ( "localhost", 11810 )'
```

2. 给协调节点 21810 设置为优先读备节点；

```shell
sdb 'db.updateConf ( { preferedinstance : "S" } , { NodeName : "sdbserver1:21810" } )'
```

操作截图：

![1542-9](https://doc.shiyanlou.com/courses/1542/1207281/5cc050358236950a6bc21880a05e6c76-0)

## 在 SparkSQL 中建表

进入 SparkSQL Beeline Shell，在 SparkSQL 实例中创建 employee 表并与 SequoiaDB 中的集合空间、集合关联。

1）登录 Beeline 连接到 SparkSQL 实例；

```shell
/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000'
```

操作截图：

![1542-10](https://doc.shiyanlou.com/courses/1542/1207281/6c2037a0c2378e76bb410347e00a6275)

2）创建 employee 表；

创建 employee 表，并且与 SequoiaDB 中的集合 company.employee 进行关联；

```sql
CREATE TABLE employee (
  empno  INT,
  ename  VARCHAR(128),
  age    INT
) USING com.sequoiadb.spark OPTIONS (
  host 'localhost:21810',
  collectionspace 'company',
  collection 'employee',
  preferredinstance 'S',
  preferredinstancemode 'random',
  preferredinstancestrict true
) ;
```

操作截图：

![1542-11](https://doc.shiyanlou.com/courses/1542/1207281/102bc1a7f7dcff9a04d7b5b2aba8fd68-0)

## 确定数据组 group1 主节点

使用 SequoiaDB 的系统命令 sdblist 确定数据组 group1 的主节点，以便确认联机交易跟统计分析是否在同数据组的不同数据节点上执行。

在 Linux Shell 中执行以下命令，确认数据组 group1 的主节点；

```shell
sdblist -l | grep -E "Name|group1"
```

操作截图：

![1542-6](https://doc.shiyanlou.com/courses/1542/1207281/aa55a5d531f21a0a80385b22e2b044f4-0)

从查询结果可以看出，数据组 group1 中，31820 节点是主节点，11820、21820 两个节点是备节点。

## 验证联机业务与统计分析的相互隔离

分别在 MySQL 端、SparkSQL 端进行对表 employee 的查询操作，会发现在不同的 SQL 实例上进行查询，在同数据组内，会从不同的数据节点上进行数据读取。下面以数据组 group1 为例进行验证。

#### 检查数据组 group1 各数据节点的数据读取量

使用 snapshot(4) 查询集合 company.employee 在数据组 group1 各数据节点的数据读取量；

```shell
sdb 'db.snapshot( 4, { Name : "company.employee" } )' | grep -E "NodeName|TotalDataRead|GroupName"
```

操作截图：

![1542-12](https://doc.shiyanlou.com/courses/1542/1207281/ec9a7587fb75937150769320d1265831-0)

#### 在 MySQL 端查询 employee 表并观察数据读取状况

1）对 employee 表进行全表查询；

```sql
SELECT * FROM company.employee ;
```

操作截图：

![1542-13](https://doc.shiyanlou.com/courses/1542/1207281/5488d39a9cc9b782e689a5f663cce6ff)

2）使用 snapshot(4) 查询集合 company.employee 在数据组 group1 各数据节点的数据读取量；

```shell
sdb 'db.snapshot( 4, { Name : "company.employee" } )' | grep -E "NodeName|TotalDataRead|GroupName"
```

操作截图：

![1542-14](https://doc.shiyanlou.com/courses/1542/1207281/c94bdeb2a4b7e744da51e32f1beba1f1-0)

从查询结果可以看出，MySQL 实例上的查询，在数据组 group1 中，主节点 31820 上的数据查询量增加了，备节点 11820、21820 两个节点上的查询量未增加。

#### 在 SparkSQL 端查询 employee 表并观察数据读取状况

1）对 employee 表进行全表查询；

```sql
SELECT * FROM employee ;
```

操作截图：

![1542-15](https://doc.shiyanlou.com/courses/1542/1207281/a16fb8d3cf373d34fa9d689395129959)

2）使用 snapshot(4) 查询集合 company.employee 在数据组 group1 各数据节点的数据读取量；

```shell
sdb 'db.snapshot( 4, { Name : "company.employee" } )' | grep -E "NodeName|TotalDataRead|GroupName"
```

操作截图：

![1542-16](https://doc.shiyanlou.com/courses/1542/1207281/6cdcf291534e90d168975d31b318e4d2-0)

从查询结果可以看出，SparkSQL 实例上的查询，在数据组 group1 中，主节点 31820 上的数据查询量没有增加，备节点 21820 上的查询量增加。

## 总结

通过本课程，我们学习了如何配置读写分离策略，保证在线联机业务与后台统计分析的相互隔离，并且学习了如何在 MySQL 实例、SparkSQL 实例中操作 SeuqoiaDB 巨杉数据库中的数据。

今天我们学到的知识点为：

+ MySQL 的使用
+ SparkSQL 的使用
+ SequoiaDB 读写分离策略的配置
+ 联机业务与统计分析的相互隔离
