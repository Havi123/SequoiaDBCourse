# 考试

## 挑战介绍

在对接好的sequoiadb和spark的环境下,熟悉sequoiadb和SparkSQL关联表的创建使用,spark的计划分析

#### 知识点

sequoiadb和spark表的关联,spark的计划分析

## 挑战内容

1) 在已搭建并对接好的sequoiadb和spark的环境中，在Sequoiadb创建集合空间company,集合employee,插入数据(id:10001, name:'Georgi', age:48);
2) 用beeline登录spark,创建对应集合空间的数据库company,对应集合的表employee,插入数据(id:10002, name:'Bezalel', age:21);
3) 在spark上查看数据内容是否正常;
4) 在sequoiadb上查看数据内容是否正常;
5) 执行计划分析:

## 挑战要求

1) 完成sequoiadb和spark关联表的创建;
2) 插入的两条数据要在spark以及sequoiadb正确显示;
3) 进行SparkSQL 执行计划的分析
 

## 示例代码
```
sequoiadb:
sdb 'db = new Sdb("localhost",11810)'
sdb 'db.createCS("company").createCL("employee")'
sdb 'db.company.employee.insert({id:10001, name:"Georgi", age:48})'
sdb 'db.company.employee.find()'

spark:
/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000'
CREATE DATABASE company;
USE company;
CREATE TABLE employee (
  id  INT,
  name  VARCHAR(128),
  age    INT
) USING com.sequoiadb.spark OPTIONS (
  host 'localhost:11810',
  collectionspace 'company',
  collection 'employee'
) ;
INSERT INTO company.employee VALUES (10002, 'Bezalel', 21) ;
SELECT * FROM company.employee;
EXPLAIN SELECT * FROM company.employee;

sequoiadb:
sdb 'db = new Sdb("localhost",11810)'
sdb 'db.company.employee.find()'
```


## 挑战配置联机交易与统计分析相互隔离

#### 挑战介绍

配置 SparkSQL 实例与 MySQL 实例连接不同的协调节点，并在 SparkSQL 连接的协调节点上配置为优先从备节点读取数据。

#### 知识点

配置联机交易与统计分析相互隔离

## 挑战内容

1) 配置 SparkSQL 实例与 MySQL 实例连接不同的协调节点；
2) 在 SparkSQL 连接的协调节点上配置为优先从备节点读取数据。

## 挑战要求

1) 配置 SparkSQL 实例与 MySQL 实例连接不同的协调节点；
2) 在 SparkSQL 连接的协调节点上配置为优先从备节点读取数据。

#### 提示

1) SparkSQL 中指定协调节点的连接是在建表的时候指定；
2) SparkSQL 建表时需要与 SequoiaDB 数据库中的集合空间和集合进行关联；
3) SparkSQL 建表时需要保证 SequoiaDB 数据库中集合空间和集合已存在；
4) SequoiaDB 数据库的读写分离可针对节点进行配置，并且在下一次连接生效。

## 示例代码
```
CREATE TABLE employee (
  id  INT,
  name  VARCHAR(128),
  age    INT
) USING com.sequoiadb.spark OPTIONS (
  host 'localhost:11810',
  collectionspace 'company',
  collection 'employee'
) ;

 bin/sdb_sql_ctl chconf myinst --sdb-conn-addr=sdbserver1:11810
```
