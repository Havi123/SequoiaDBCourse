## 考试介绍

此考试是在安装部署 SequoiaDB 巨杉数据库、MySQL 和 SparkSQL 实例的环境中进行如下操作：
- 在 SequoiaDB 巨杉数据库中创建集合关联 SparkSQL 实例的映射表，进行数据查询；
- 配置 SparkSQL 实例与 MySQL 实例连接不同的协调节点，并设置 SparkSQL 优先从备节点读取数据；



> Note:
> - 考试内容需在系统用户 `sdbadmin` 下完成，用户密码为 `sdbadmin`
> - SequoiaDB 巨杉数据库安装目录（/opt/sequoiadb）
> - SparkSQL 实例安装目录（/opt/spark）
> - MySQL 实例安装目录（/opt/sequoiasql/mysql）

#### 知识点

1）在 SequoiaDB 巨杉数据库引擎中创建数据域、集合空间和集合；

2）SequoiaDB 巨杉数据库中的集合和 SparkSQL 实例的表关联，分析执行计划；

3）配置联机交易与统计分析相互隔离；

## 考试内容

1）切换到 sdbadmin 用户；

2）在 SequoiaDB 数据库上创建集合空间 company，集合 employee，写入如下数据：

- ( empno: 10001, ename: 'Georgi', age: 48 )；
- ( empno: 10002, ename: 'Bezalel', age: 21 )；
- ( empno: 10003, ename: 'Parto', age: 33 )；

> Note:
>
>  该考试环境为单分区三副本，仅创建了数据组 `group1` 

3）在 MySQL 实例创建数据库 company 和 数据表 employee 与 SequoiaDB 巨杉数据库存储引擎的 employee 集合映射；

4）查看当前 MySQL 实例连接 SequoiaDB 巨杉数据库引擎的协调节点端口是否为11810；

5）使用 beeline 客户端连接 SparkSQL 的 thriftserver 服务，创建对应集合空间的数据库 company，对应集合的表 employee；建表要求：
- 设置连接 SequoiaDB 的协调节点为 21810；
- 设置 SparkSQL 读取数据时优先选择备节点；

6）查找年龄最小的员工信息并写入 company.result 表中（使用结果集创建表的方式，包含 empno，ename， age 三个字段）；

7）使用 SELECT 方法查看数据；

8）使用 explain 分析任意 SQL 的执行计划；


## 考试要求

1）完成 SequoiaDB 和 SparkSQL 关联表的创建；

2）进行 SparkSQL 执行计划的分析；

3）配置 SparkSQL 实例与 MySQL 实例连接不同的协调节点；

4）在 SparkSQL 连接的协调节点上配置为优先从备节点读取数据；

<!--
测试判断:
1. 查看sdb数据是否正常; /opt/sequoiadb/bin/sdb 'db = new Sdb(); db.company.employee.find()' | grep 10001 ;SequoiaDB 数据异常

2. 查看spark数据是否正常; /opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000' -e 'SELECT * FROM company.employee WHERE empno IN ("10001", "10002");' | grep -E "10002"; Spark数据异常

示例代码：
1.
sdb 'db = new Sdb(); db.createCS("company").createCL("employee")'
sdb 'db.company.employee.insert({empno : 10001, ename : "Georgi", age : 48})'

-->



<!--
测试判断：
1. 查看优先备节点是否设置； cat /opt/sequoiadb/conf/local/21810/sdb.conf | grep -i  "PreferInstance=S"; 协调节点 21810 优先读取备数据节点配置错误
2. 查看spark协调节点配置;/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000' -e 'show create table company.employee' | grep 21810; spark 建表协调节点配置错误，需要指定优先读取备节点数据的协调节点哦


示例代码：
1.
sdb 'db = new Sdb(); db.createCS("company").createCL("employee")'

2.
sdb 'db.updateConf({preferinstance:"S"},{NodeName:"sdbserver1:21810"})'

/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000' -e 'create database  if not exists company;drop table  if exists company.employee; create table company.employee ( empno int, ename varchar(128), age int)using com.sequoiadb.spark options( host "localhost:21810", collectionspace "company", collection "employee");'

/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000' -e 'insert into company.employee values ( 10001, 'Georgi', 48 ),( 10002, 'Bezalel', 21 ),( 10003, 'Parto', 33 ),( 10004, 'Chirstian', 40 ),( 10005, 'Kyoichi', 23 ),( 10006, 'Anneke', 19 ),( 10007, 'Ileana', 28 ),( 10008, 'Liz', 38 ),( 10009, 'Parish', 31 ),( 10010, 'Odette', 23 );'

/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000' -e 'CREATE TABLE company.result USING com.sequoiadb.spark OPTIONS 
(
host "localhost:11810",
collectionspace "company",
collection "result"
) AS SELECT * FROM company.employee;'
-->
