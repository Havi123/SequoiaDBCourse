# 考试

## 挑战介绍

Spark 作为一种快速、通用、可扩展的大数据分析引擎，是当前大数据时代数据处理中不可缺少的数据并行计算框架，它基于内存计算，在保证了数据处理的实时性的同时还保证了高容错性和高可伸缩性，允许用户将 Spark 集群部署在大量廉价的硬件之中。

本挑战是在已搭建并对接好的 SequoiaDB 和 Spark 的环境中，使用 Spark-SequoiaDB 连接组件，将 SequoiaDB 可以作为 Spark 的数据源，从而可以通过 SparkSQL 实例对 SequoiaDB 巨杉数据库存储引擎的数据进行查询、统计操作，从而熟悉 SequoiaDB 和 SparkSQL 关联表的创建使用，Spark 的执行计划分析等操作。

#### 知识点

SequoiaDB 和 Spark 表的关联，Spark 的执行计划分析

## 挑战内容

1) 在 SequoiaDB 数据库上创建集合空间 company，集合 employee，插入数据 ( empno : 10001, ename : 'Georgi', age : 48 )；

2) 用 beeline 登录 Spark，创建对应集合空间的数据库 company，对应集合的表 employee，插入数据 ( empno : 10002, ename : 'Bezalel', age : 21 )；

3) 在 Spark 上查看数据内容是否正常；

4) 在 SequoiaDB 上查看数据内容是否正常；

5) 执行计划分析。

## 挑战要求

1) 完成 SequoiaDB 和 Spark 关联表的创建；

2) 插入的两条数据要在 Spark 以及 SequoiaDB 正确显示；

3) 进行 SparkSQL 执行计划的分析。

<!--
测试判断:
1. 查看sdb数据是否正常; /opt/sequoiadb/bin/sdb 'db = new Sdb(); db.company.employee.find()' | grep 10001 ;SequoiaDB 数据异常

2. 查看spark数据是否正常; /opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000' -e 'SELECT * FROM company.employee where empno in ("10001", "10002");' | grep -E "10002"; Spark数据异常

示例代码：
1.
sdb 'db = new Sdb(); db.createCS("company").createCL("employee")'
sdb 'db.company.employee.insert({empno : 10001, ename : "Georgi", age : 48})'

2. 
/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000' -e 'create database company; create table company.employee ( empno int, ename varchar(128), age int)using com.sequoiadb.spark options( host "localhost:11810", collectionspace "company", collection "employee");'

/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000' -e 'insert into company.employee values( 10002, "Bezalel", 21);'
-->

## 挑战配置联机交易与统计分析相互隔离

#### 挑战介绍

配置 SparkSQL 实例与 MySQL 实例连接不同的协调节点，并在 SparkSQL 连接的协调节点上配置为优先从备节点读取数据。

#### 知识点

配置联机交易与统计分析相互隔离

## 挑战内容

1) 创建集合空间 company，集合 employee；

2) 在 MySQL 实例创建 SequoiaSDB 映射表,并插入数据 ( 10001, 'Georgi', 48 )，( 10002, 'Bezalel', 21 )，( 10003, 'Parto', 33 )，( 10004, 'Chirstian', 40 )，( 10005, 'Kyoichi', 23 )，( 10006, 'Anneke', 19 )，( 10007, 'Ileana', 28 )，( 10008, 'Liz', 38 )，( 10009, 'Parish', 31 )，( 10010, 'Odette', 23 )；
  
3) 将协调节点 21810 设置为只读备节点， SparkSQL 连接协调节点 21810；

4) 确认数据组中 11820 为主节点，检查数据组 1 各数据节点的数据读取量。

## 挑战要求

1) 配置 SparkSQL 实例与 MySQL 实例连接不同的协调节点；

2) 在 SparkSQL 连接的协调节点上配置为优先从备节点读取数据。

#### 提示

1) SparkSQL 中指定协调节点的连接是在建表的时候指定；

2) SparkSQL 中与 SequoiaDB 关联的表，如果想要修改参数，可对 SparkSQL 表进行重建，并使用正确参数；

3) SparkSQL 建表时需要与 SequoiaDB 数据库中的集合空间和集合进行关联；

4) SparkSQL 建表时需要保证 SequoiaDB 数据库中集合空间和集合已存在；

5) SequoiaDB 数据库的读写分离可针对节点进行配置，并且在下一次连接生效。

<!--
测试判断：
1. 查看优先备节点是否设置； cat /opt/sequoiadb/conf/local/21810/sdb.conf | grep -i  "PreferInstance=S"; 协调节点 21810 优先读取备数据节点配置错误
2. 查看spark协调节点配置;/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000' -e 'show create table company.employee' | grep 21810; spark 建表协调节点配置错误，需要指定优先读取备节点数据的协调节点哦

示例代码：
1.
sdb 'db = new Sdb(); db.createCS("company").createCL("employee")'

2.
sdb 'db.updateConf({preferinstance:"S"},{NodeName:"sdbserver1:21810"})'

/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000' -e 'create database  if not exists company;drop table  if exists company.employee; create table company.employee ( empno int, ename varchar(128), age int)using com.sequoiadb.spark options( host "localhost:21810", collectionspace "company", collection "employee");'

/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000' -e 'insert into company.employee values ( 10001, 'Georgi', 48 ),( 10002, 'Bezalel', 21 ),( 10003, 'Parto', 33 ),( 10004, 'Chirstian', 40 ),( 10005, 'Kyoichi', 23 ),( 10006, 'Anneke', 19 ),( 10007, 'Ileana', 28 ),( 10008, 'Liz', 38 ),( 10009, 'Parish', 31 ),( 10010, 'Odette', 23 );'
-->
