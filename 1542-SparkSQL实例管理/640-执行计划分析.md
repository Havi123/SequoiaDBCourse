---
show: step
version: 2.0 
enable_checker: true 
---

# 执行计划分析

## 课程介绍

本课程将带领您在已经部署 SequoiaDB 巨杉数据库引擎及创建了 MySQL 实例、SparkSQL 实例的环境中，查看 SparkSQL 的执行计划，并进行分析。

#### 请点击右侧选择使用的实验环境

#### 知识点

+ SparkSQL 执行计划的查看
+ SparkSQL 执行计划的分析

## 切换用户及查看数据库版本

#### 切换到 sdbadmin 用户

部署 SequoiaDB 巨杉数据库和 SequoiaSQL-MySQL 实例的操作系统用户为 sdbadmin。

```shell
su - sdbadmin
```

>Note:
>
>用户 sdbadmin 的密码为 `sdbadmin` 。

#### 查看巨杉数据库版本

查看 SequoiaDB 巨杉数据库引擎版本；

```shell
sequoiadb --version
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1469/1207281/b4082b0d6d6bdf89d229aa713a53759d)

## 查看节点启动列表

查看 SequoiaDB 巨杉数据库引擎节点列表；

```shell
sdblist
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1469/1207281/02fcaa58ac27e91688ead137fa748d6e)

>Note:
>
>如果显示的节点数量与预期不符，请稍等初始化完成并重试该步骤。

## Spark 进程检查

查看 Spark 的 Worker 和 Master 是否已经启动；

```shell
jps
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1542/1207281/892e0fbf13b71ea9762ff760a764ac5c-0)

>Note:
>
>如果显示的进程名称和数量与预期不符，请稍等初始化完成并重试该步骤。

## 初始化数据

#### 在 SequoiaDB 中建立集合空间和集合

1）使用 Linux 命令进入 SequoiaDB Shell 命令行；

```shell
sdb
```

2）连接 SequoiaDB 数据库；

```javascript
var db = new Sdb ( "localhost", 11810 ) ;
```

2）创建 company_domains 逻辑域；

```javascript
db.createDomain ( "company_domains", ["group1", "group2", "group3"], { AutoSplit : true } ) ;
```

3）创建 company 集合空间；

```javascript
db.createCS ( "company", { Domain : "company_domains" } ) ;
```

4）创建 employee 集合；

```javascript
db.company.createCL ( "employee", {"ShardingKey" : { "_id" : 1} , "ShardingType" : "hash" , "ReplSize" : -1 , "Compressed" : true , "CompressionType" : "lzw" , "AutoSplit" : true , "EnsureShardingIndex" : false } ) ;
```

5）退出 SequoiaDB Shell；

```shell
quit ;
```

操作截图：

![1542-640-1](https://doc.shiyanlou.com/courses/1542/1207281/d5469fa5acc0275bfa62236a6e6d5e34)

#### 在 SparkSQL 中关联 SequoiaDB 的集合空间、集合

进入 SparkSQL Beeline Shell，在 SparkSQL 实例中创建 employee 表并与 SequoiaDB 中的集合空间、集合关联。

1）登录 Beeline 连接到 SparkSQL 实例；

```shell
/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000'
```

2）创建 employee 表；

创建 employee 表，并且与 SequoiaDB 中的集合 company.employee 进行关联

```sql
CREATE TABLE employee (
  empno  INT,
  ename  VARCHAR(128),
  age    INT
) USING com.sequoiadb.spark OPTIONS (
  host 'localhost:11810',
  collectionspace 'company',
  collection 'employee'
) ;
```

操作截图：

![1542-610-2](https://doc.shiyanlou.com/courses/1542/1207281/324fbfcf6f78845eb39ae378ed6c9ff6)

3）在 SparkSQL 中插入数据；

```sql
INSERT INTO employee VALUES (10001, 'Georgi', 48) ;
INSERT INTO employee VALUES (10002, 'Bezalel', 21) ;
INSERT INTO employee VALUES (10003, 'Parto', 33) ;
INSERT INTO employee VALUES (10004, 'Chirstian', 40) ;
```

操作截图：

![1542-610-3](https://doc.shiyanlou.com/courses/1542/1207281/dd7cd19a88f736d5e7964e8cb4cc2a53)

## 查看执行计划并分析

1）执行查询 SQL；

```sql
SELECT * FROM employee WHERE empno = 10003 ;
```

操作截图：

![1542-610-4](https://doc.shiyanlou.com/courses/1542/1207281/1b558227b3fb7e3ff724e2ea0979ff8f)

2）查看执行计划；

```sql
EXPLAIN SELECT * FROM employee WHERE empno = 10003 ;
```

操作截图：

![1542-610-5](https://doc.shiyanlou.com/courses/1542/1207281/d6d3e6d397fe7c1aac142d4b1af4d7de)

执行计划查询结果分析如下：

+ Scan：表示此查询扫描的 Spark 表；
+ PushedFilters：表示过滤条件，包括 empno 不为空和 empno = 10003 这两个条件；
+ ReadSchema：表示查询的字段名和对应的类型。

## 总结

通过本课程，我们学习了如何查看 SparkSQL 的执行计划，并且简单学习了如何进行 SparkSQL 执行计划的分析。

#### 知识点总结

+ SparkSQL 执行计划的查看
+ SparkSQL 执行计划的分析
