---
show: step
version: 9.0 
enable_checker: true 
---
# 执行计划分析

## 课程介绍

本课程将带领您在已经部署 SequoiaDB 巨杉数据库引擎及创建了 MySQL 实例、SparkSQL 实例的环境中，查看 SparkSQL 的执行计划，并进行分析。

#### 请点击右侧选择使用的实验环境

#### 环境架构：

本课程中 SequoiaDB 巨杉数据库的集群拓扑结构为三分区单副本，其中包括：1 个 SequoiaSQL-SparkSQL 数据库实例节点， 1 个引擎协调节点， 1 个编目节点与 3 个数据节点。

![图片描述](https://doc.shiyanlou.com/courses/1542/1207281/50d088eb3f655c3058e4ee9ea6a29446-0)

详细了解 SequoiaDB 巨杉数据库系统架构：

* [SequoiaDB 系统架构](http://doc.sequoiadb.com/cn/sequoiadb-cat_id-1519649201-edition_id-0)

#### 实验环境

课程使用的实验环境为 Ubuntu Linux 16.04 64 位版本；SequoiaDB 巨杉数据库引擎以及 SequoiaSQL-MySQL 实例和 SequoiaDB-SparkSQL 实例连接器均为 3.4 版本；Spark 版本为2.4.4；JDK 版本为 openjdk1.8。

## 切换用户及查看数据库版本

#### 切换到 sdbadmin 用户

部署 SequoiaDB 巨杉数据库和 SequoiaSQL-MySQL 实例的操作系统用户为 sdbadmin。

```shell
su - sdbadmin
```

>Note:
>
>用户 sdbadmin 的密码为 `sdbadmin` 。

#### 查看巨杉数据库版本

查看 SequoiaDB 巨杉数据库引擎版本：

```shell
sequoiadb --version
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1538/1207281/6cccf5951f048e01b4789f3c08483bb0-0)

## 查看节点启动列表

查看 SequoiaDB 巨杉数据库引擎节点列表：

```shell
sdblist
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1538/1207281/810c1187bb311b8a506bdb6731e1f73f-0)

>Note:
>
>如果显示的节点数量与预期不符，请稍等初始化完成并重试该步骤。
> 
>C: 编目节点，S：协调节点，D：数据节点

## Spark 进程检查

查看 Spark 的 Worker 和 Master 是否已经启动：

```shell
jps
```

操作截图：

![图片描述](https://doc.shiyanlou.com/courses/1543/1207281/3b2fda51ba13a1f1befdd61746844f44-0)

>Note:
>
>如果显示的进程名称和数量与预期不符，请稍等初始化完成并重试该步骤。

## 初始化数据

#### 在 SequoiaDB 中建立集合空间和集合

1）使用 Linux 命令进入 SequoiaDB Shell 命令行；

```shell
sdb
```

2）连接 SequoiaDB 数据库；

```javascript
var db = new Sdb("localhost", 11810);
```

2）创建 company_domains 逻辑域；

```javascript
db.createDomain("company_domains", [ "group1", "group2", "group3" ], { AutoSplit: true } );
```

3）创建 company 集合空间；

```javascript
db.createCS("company", { Domain: "company_domains" } );
```

4）创建 employee 集合；

```javascript
db.company.createCL("employee", {"ShardingKey": { "_id": 1}, "ShardingType": "hash", "ReplSize": -1, "Compressed": true, "CompressionType": "lzw", "AutoSplit": true, "EnsureShardingIndex": false } );
```

5）退出 SequoiaDB Shell；

```shell
quit;
```

操作截图：

![1542-640-1](https://doc.shiyanlou.com/courses/1542/1207281/8a986975b479eecf299fb94eeaeb682f-0)

#### 在 SparkSQL 中关联 SequoiaDB 的集合空间、集合

进入 SparkSQL Beeline Shell，在 SparkSQL 实例中创建 employee 表并与 SequoiaDB 中的集合空间、集合关联。

1）登录 Beeline 连接到 SparkSQL 实例；

```shell
/opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000'
```

2）创建并切换至 company 数据库；

```sql
CREATE DATABASE company;
USE company;
```

3）创建 employee 表；

创建 employee 表，并且与 SequoiaDB 中的集合 company.employee 进行关联：

```sql
CREATE TABLE employee 
(
empno  INT,
ename  String,
age    INT
) 
USING com.sequoiadb.spark OPTIONS 
(
host 'localhost:11810',
collectionspace 'company',
collection 'employee'
);
```

操作截图：

![1542-610-2](https://doc.shiyanlou.com/courses/1542/1207281/d7a5eff343875353beceb0dcd359c4f4-0)

4）在 SparkSQL 中插入数据；

```sql
INSERT INTO employee VALUES ( 10001, 'Georgi', 48 );
INSERT INTO employee VALUES ( 10002, 'Bezalel', 21 );
INSERT INTO employee VALUES ( 10003, 'Parto', 33 );
INSERT INTO employee VALUES ( 10004, 'Chirstian', 40 );
```

操作截图：

![1542-610-3](https://doc.shiyanlou.com/courses/1543/1207281/6d7c7a5d31b09c8bce451aa1c5a32a4d-0)

## 查看执行计划并分析

1）执行查询 SQL；

```sql
SELECT * FROM employee WHERE empno = 10003;
```

操作截图：

![1542-610-4](https://doc.shiyanlou.com/courses/1543/1207281/029675aabca0ca3f980d37bcf77c3292-0)

2）查看执行计划；

```sql
EXPLAIN SELECT * FROM employee WHERE empno = 10003;
```

操作截图：

![1542-610-5](https://doc.shiyanlou.com/courses/1542/1207281/f8578e7f6826bab7ea3b77979f0a07ad-0)

执行计划查询结果分析如下：

+ Scan：表示此查询扫描的 Spark 表；
+ PushedFilters：表示过滤条件，包括 empno 不为空和 empno = 10003 这两个条件；
+ ReadSchema：表示查询的字段名和对应的类型。

<!--
## SequoiaDB-SparkSQL 连接器优化

对于数据量庞大的表来说，使用高效的数据读取模式有助于提高查询效率，下面主要介绍 partitionmode 参数的不同配置对 SparkSQL 查询的影响，如果想了解更详细的分析，可参考 [SparkSQL + SequoiaDB 性能调优策略](http://blog.sequoiadb.com/cn/detail-id-112)。

partitionmode 参数在创建 SequoiaDB-SparkSQL 关联表时指定，表示连接器的分区模式，可选值为“single”、“sharding”、“datablock”和“auto”，默认值为“auto”。下面介绍一下各个值的含义：

1. single ：SparkSQL 在访问 SequoiaDB 数据时，不考虑并发性能，只用一个线程连接 SequoiaDB 的协调节点，一般在建表做表结构数据抽样时采用；

2. sharding ：SparkSQL 在访问 SequoiaDB 数据时，采用直接连接SequoiaDB 各个数据节点的方式，可以根据索引筛选数据；一般用于 SQL 命令包含查询条件，并且该查询可以在 SequoiaDB 中使用索引的场景；

3. datablock ：SparkSQL 在访问 SequoiaDB 数据时，采用并发连接SequoiaDB 的数据块进行数据读取，读取所有的数据块；一般用于 SQL 命令无法在 SequoiaDB 中使用索引查询，并且查询的数据量较大的场景；

4. auto ：SparkSQL 在向 SequoiaDB 查询数据时，由连接器根据不同的情况分析决定，此次查询访问 SequoiaDB 数据的方式使用“sharding”或者“datablock”。

>Note:
>
>在使用 datablock 模式访问 SequoiaDB 数据访问时，有以下两个参数可以搭配使用：
>
>partitionblocknum ：表示每个 Spark Worker 在进行数据计算时，一次获取多少个 SequoiaDB 数据块读取任务，默认值为 4；当查询的目标表数据块较多时，应增大该参数值以提高数据读取效率。
>
>partitionmaxnum ：表示连接器最多能够生成多少个数据块读取任务，该参数的默认值为 1000；当查询的目标表数据块较多时，应增大该参数值以减少计算 Spark task 数量的时间。

partitionmode 参数的配置选择需要根据实际情况进行分析。一般来说，对于能够走索引并且查询条件字段趋向于唯一的查询，推荐使用 sharding 模式，这样能够精准命中需要查询的数据；对于能够走索引但是查询返回结果集很大的查询，推荐使用 datablock 模式，这样在数据读取时进行顺序读取可以避免大量的随机 IO，提高数据读取效率。

-->


## 总结

通过本课程，我们学习了如何查看 SparkSQL 的执行计划，并且简单学习了如何进行 SparkSQL 执行计划的分析。

#### 知识点总结

+ SparkSQL 执行计划的查看
+ SparkSQL 执行计划的分析
